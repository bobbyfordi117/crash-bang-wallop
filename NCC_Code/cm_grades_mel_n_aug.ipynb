{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99d083a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T19:14:57.522194Z",
     "iopub.status.busy": "2022-07-12T19:14:57.521682Z",
     "iopub.status.idle": "2022-07-12T19:14:58.389353Z",
     "shell.execute_reply": "2022-07-12T19:14:58.388523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_path</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/fold_2/Bright_Black_10.wav</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/fold_2/Bright_Black_100.wav</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/fold_2/Bright_Black_101.wav</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/fold_2/Bright_Black_102.wav</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/fold_2/Bright_Black_103.wav</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  relative_path  Y2\n",
       "0   /fold_2/Bright_Black_10.wav   9\n",
       "1  /fold_2/Bright_Black_100.wav   7\n",
       "2  /fold_2/Bright_Black_101.wav   7\n",
       "3  /fold_2/Bright_Black_102.wav   7\n",
       "4  /fold_2/Bright_Black_103.wav   7"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ALTERED FROM:https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5\n",
    "#READ METADATA FILE FOR TRAINING DATA\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Read metadata file\n",
    "metadata_file = r'/home2/qlpd78/crash-bang-wallop/data/data/metadata_2/METADATA_2.csv'\n",
    "df = pd.read_csv(metadata_file)\n",
    "df.head()\n",
    "\n",
    "# Construct file path by concatenating fold and file name\n",
    "df['relative_path'] = '/' + df['AUDIO'].astype(str)\n",
    "\n",
    "# Take relevant columns\n",
    "df = df[['relative_path', 'Y2']]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29f0796",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T19:14:58.394939Z",
     "iopub.status.busy": "2022-07-12T19:14:58.394654Z",
     "iopub.status.idle": "2022-07-12T19:15:00.171845Z",
     "shell.execute_reply": "2022-07-12T19:15:00.171321Z"
    }
   },
   "outputs": [],
   "source": [
    "import math, random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def confusion_matrix_func():\n",
    "  y_pred = []\n",
    "  y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "  for data in val_dl:\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "    inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "    output = myModel(inputs) # Feed Networ\n",
    "\n",
    "    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "    y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "    labels = labels.data.cpu().numpy()\n",
    "    y_true.extend(labels) # Save Truth\n",
    "#print(y_pred)\n",
    "#print(y_true)\n",
    "# constant for classes\n",
    "  classes = (\"St316\", \"St430\", \"St304\", \"En24\", \"BD2\", \"En3B\", \"En1A\", \"Black\", \"Galvanised\", \"Bright\" )\n",
    "\n",
    "# Build confusion matrix\n",
    "  cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "  df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10 , index = [i for i in classes],\n",
    "                      columns = [i for i in classes])\n",
    "  fig=plt.figure(figsize = (12,7))\n",
    "  sn.heatmap(df_cm, annot=True)\n",
    "  run[\"train/confusion_matrix\"].upload(fig)\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "class AudioUtil():\n",
    "  # ----------------------------\n",
    "  # Load an audio file. Return the signal as a tensor and the sample rate\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def open(audio_file):\n",
    "    sig, sr = torchaudio.load(audio_file)\n",
    "    return (sig, sr)\n",
    "#convert mono to stereo\n",
    "   # ----------------------------\n",
    "  # Convert the given audio to the desired number of channels\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def rechannel(aud, new_channel):\n",
    "    sig, sr = aud\n",
    "\n",
    "    if (sig.shape[0] == new_channel):\n",
    "      # Nothing to do\n",
    "      return aud\n",
    "\n",
    "    if (new_channel == 1):\n",
    "      # Convert from stereo to mono by selecting only the first channel\n",
    "      resig = sig[:1, :]\n",
    "    else:\n",
    "      # Convert from mono to stereo by duplicating the first channel\n",
    "      resig = torch.cat([sig, sig])\n",
    "\n",
    "    return ((resig, sr))\n",
    " # ----------------------------\n",
    "  # Since Resample applies to a single channel, we resample one channel at a time\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def resample(aud, newsr):\n",
    "    sig, sr = aud\n",
    "\n",
    "    if (sr == newsr):\n",
    "      # Nothing to do\n",
    "      return aud\n",
    "\n",
    "    num_channels = sig.shape[0]\n",
    "    # Resample first channel\n",
    "    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
    "    if (num_channels > 1):\n",
    "      # Resample the second channel and merge both channels\n",
    "      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
    "      resig = torch.cat([resig, retwo])\n",
    "\n",
    "    return ((resig, newsr))\n",
    " # ----------------------------\n",
    "  # Pad (or truncate) the signal to a fixed length 'max_ms' in milliseconds\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def pad_trunc(aud, max_ms):\n",
    "    sig, sr = aud\n",
    "    num_rows, sig_len = sig.shape\n",
    "    max_len = sr//1000 * max_ms\n",
    "\n",
    "    if (sig_len > max_len):\n",
    "      # Truncate the signal to the given length\n",
    "      sig = sig[:,:max_len]\n",
    "\n",
    "    elif (sig_len < max_len):\n",
    "      # Length of padding to add at the beginning and end of the signal\n",
    "      pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "      pad_end_len = max_len - sig_len - pad_begin_len\n",
    "\n",
    "      # Pad with 0s\n",
    "      pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "      pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "\n",
    "      sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
    "      \n",
    "    return (sig, sr)\n",
    " # ----------------------------\n",
    "  # Shifts the signal to the left or right by some percent. Values at the end\n",
    "  # are 'wrapped around' to the start of the transformed signal.\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def time_shift(aud, shift_limit):\n",
    "    sig,sr = aud\n",
    "    _, sig_len = sig.shape\n",
    "    shift_amt = int(random.random() * shift_limit * sig_len)\n",
    "    return (sig.roll(shift_amt), sr)\n",
    "  # ----------------------------\n",
    "  # Generate a Spectrogram\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
    "    sig,sr = aud\n",
    "    top_db = 80\n",
    "\n",
    "    # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len)(sig)\n",
    "\n",
    "    # Convert to decibels\n",
    "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "    return (spec)\n",
    "  # ----------------------------\n",
    "  # Augment the Spectrogram by masking out some sections of it in both the frequency\n",
    "  # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent\n",
    "  # overfitting and to help the model generalise better. The masked sections are\n",
    "  # replaced with the mean value.\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "    _, n_mels, n_steps = spec.shape\n",
    "    mask_value = spec.mean()\n",
    "    aug_spec = spec\n",
    "\n",
    "    freq_mask_param = max_mask_pct * n_mels\n",
    "    for _ in range(n_freq_masks):\n",
    "      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    time_mask_param = max_mask_pct * n_steps\n",
    "    for _ in range(n_time_masks):\n",
    "      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    return aug_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8df43b97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T19:15:00.175178Z",
     "iopub.status.busy": "2022-07-12T19:15:00.174945Z",
     "iopub.status.idle": "2022-07-12T19:15:00.181941Z",
     "shell.execute_reply": "2022-07-12T19:15:00.181419Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchaudio\n",
    "\n",
    "# ----------------------------\n",
    "# Sound Dataset\n",
    "# ----------------------------\n",
    "class SoundDS(Dataset):\n",
    "  def __init__(self, df, data_path):\n",
    "    self.df = df\n",
    "    self.data_path = str(data_path)\n",
    "    self.duration = 4000\n",
    "    self.sr = 44100\n",
    "    self.channel = 2\n",
    "    self.shift_pct = 0.4\n",
    "            \n",
    "  # ----------------------------\n",
    "  # Number of items in dataset\n",
    "  # ----------------------------\n",
    "  def __len__(self):\n",
    "    return len(self.df)    \n",
    "    \n",
    "  # ----------------------------\n",
    "  # Get i'th item in dataset\n",
    "  # ----------------------------\n",
    "  def __getitem__(self, idx):\n",
    "    # Absolute file path of the audio file - concatenate the audio directory with\n",
    "    # the relative path\n",
    "    audio_file = self.data_path + self.df.loc[idx, 'relative_path']\n",
    "    # Get the Class ID\n",
    "    class_id = self.df.loc[idx, 'Y2']\n",
    "\n",
    "    aud = AudioUtil.open(audio_file)\n",
    "    # Some sounds have a higher sample rate, or fewer channels compared to the\n",
    "    # majority. So make all sounds have the same number of channels and same \n",
    "    # sample rate. Unless the sample rate is the same, the pad_trunc will still\n",
    "    # result in arrays of different lengths, even though the sound duration is\n",
    "    # the same.\n",
    "    reaud = AudioUtil.resample(aud, self.sr)\n",
    "    rechan = AudioUtil.rechannel(reaud, self.channel)\n",
    "\n",
    "    dur_aud = AudioUtil.pad_trunc(rechan, self.duration)\n",
    "    shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct)\n",
    "    sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "    #aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "\n",
    "    return sgram, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04d5005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T19:15:00.184900Z",
     "iopub.status.busy": "2022-07-12T19:15:00.184578Z",
     "iopub.status.idle": "2022-07-12T19:15:00.202422Z",
     "shell.execute_reply": "2022-07-12T19:15:00.201687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1878\n",
      "470\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "\n",
    "def inference (model, val_dl):\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "    wrong=[]\n",
    "\n",
    "  # Disable gradient updates\n",
    "    with torch.no_grad():\n",
    "        for data in val_dl:\n",
    "      # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "      # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "      # Get predictions\n",
    "            outputs = model(inputs)\n",
    "\n",
    "      # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            cpu_prediction = prediction.cpu().numpy()\n",
    "            cpu_labels = labels.cpu().numpy()\n",
    "            for i in range(len(cpu_prediction)):\n",
    "                if cpu_prediction[i]!=cpu_labels[i]:\n",
    "                    wrong.append([cpu_prediction[i],cpu_labels[i]])\n",
    "                    \n",
    "      # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "    #print(wrong)\n",
    "    acc = correct_prediction/total_prediction\n",
    "    print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
    "    return acc,wrong\n",
    "\n",
    "\n",
    "\n",
    "#add code to run inference on every epoch of the training?\n",
    "data_path=r'/home2/qlpd78/crash-bang-wallop/data/data' #change user (krsd48) as needed\n",
    "myds = SoundDS(df, data_path)\n",
    "\n",
    "\n",
    "# Random split of 80:20 between training and validation\n",
    "num_items = len(myds)\n",
    "num_train = round(num_items * 0.8)\n",
    "num_val = num_items - num_train\n",
    "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
    "# Create training and validation data loaders\n",
    "train_dl =torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False)\n",
    "print(num_train)\n",
    "print(num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7511a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T19:15:00.206083Z",
     "iopub.status.busy": "2022-07-12T19:15:00.205776Z",
     "iopub.status.idle": "2022-07-12T19:15:33.604874Z",
     "shell.execute_reply": "2022-07-12T19:15:33.603834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Audio Classification Model\n",
    "# ----------------------------\n",
    "class AudioClassifier (nn.Module):\n",
    "    # ----------------------------\n",
    "    # Build the model architecture\n",
    "    # ----------------------------\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv_layers = []\n",
    "\n",
    "        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization\n",
    "        self.conv1 = nn.Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        init.kaiming_normal_(self.conv1.weight, a=0.1)\n",
    "        self.conv1.bias.data.zero_()\n",
    "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        init.kaiming_normal_(self.conv2.weight, a=0.1)\n",
    "        self.conv2.bias.data.zero_()\n",
    "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        init.kaiming_normal_(self.conv3.weight, a=0.1)\n",
    "        self.conv3.bias.data.zero_()\n",
    "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        init.kaiming_normal_(self.conv4.weight, a=0.1)\n",
    "        self.conv4.bias.data.zero_()\n",
    "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
    "\n",
    "        # Linear Classifier\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.lin = nn.Linear(in_features=64, out_features=10)\n",
    "\n",
    "        # Wrap the Convolutional Blocks\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    " \n",
    "    # ----------------------------\n",
    "    # Forward pass computations\n",
    "    # ----------------------------\n",
    "    def forward(self, x):\n",
    "        # Run the convolutional blocks\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # Adaptive pool and flatten for input to linear layer\n",
    "        x = self.ap(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Linear layer\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Final output\n",
    "        return x\n",
    "\n",
    "# Create the model and put it on the GPU if available\n",
    "myModel = AudioClassifier()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "myModel = myModel.to(device)\n",
    "# Check that it is on Cuda\n",
    "next(myModel.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c017f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T19:15:33.608357Z",
     "iopub.status.busy": "2022-07-12T19:15:33.607881Z",
     "iopub.status.idle": "2022-07-12T19:16:57.935011Z",
     "shell.execute_reply": "2022-07-12T19:16:57.933979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/crshbng/Crash/e/CRAS-30\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/qlpd78/anaconda3/lib/python3.9/site-packages/torchaudio/functional/functional.py:507: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (513) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38, Total items: 470\n",
      "Epoch: 0, Loss: 2.09, Accuracy: 0.34, Validation Accuracy: 0.38\n",
      "Finished Training\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for the remaining 13 operations to synchronize with Neptune. Do not kill this process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 13 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/crshbng/Crash/e/CRAS-30\n"
     ]
    }
   ],
   "source": [
    "import neptune.new as neptune\n",
    "num_epochs=100\n",
    "\n",
    "run = neptune.init(\n",
    "    project=\"crshbng/Crash\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI5YTdjYjc1OC0wMzliLTQwYzMtODRhZS05NDMzYTJjN2M0MmEifQ==\",\n",
    ")  # your credentials\n",
    "params = {\n",
    "    \"Num. Readings\": num_items,\n",
    "    \"Num. Types\": 5,\n",
    "    \"Type of ML\": 'CNN Classification',\n",
    "    \"n_epochs\": num_epochs,\n",
    "    \"Optimizer\": \"Adam\",\n",
    "    \"Batch Size\": 16,\n",
    "    \"Kernal Size\": (5,3,3,3),\n",
    "    \"Var\":\"mel_non-aug_cm_grades\",\n",
    "    \"Owner\": \"Freya\"\n",
    "}\n",
    "\n",
    "run[\"parameters\"] = params\n",
    "\n",
    "import datetime\n",
    "\n",
    "# ----------------------------\n",
    "# Training Loop\n",
    "# ----------------------------\n",
    "def training(model, train_dl, num_epochs):\n",
    "  # Loss Function, Optimizer and Scheduler\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                steps_per_epoch=int(len(train_dl)),\n",
    "                                                epochs=num_epochs,\n",
    "                                                anneal_strategy='linear')\n",
    "\n",
    "  # Repeat for each epoch\n",
    "  for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "\n",
    "    # Repeat for each batch in the training set\n",
    "    for i, data in enumerate(train_dl):\n",
    "        # Get the input features and target labels, and put them on the GPU\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Normalize the inputs\n",
    "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "        inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Keep stats for Loss and Accuracy\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Get the predicted class with the highest score\n",
    "        _, prediction = torch.max(outputs,1)\n",
    "        # Count of predictions that matched the target label\n",
    "        correct_prediction += (prediction == labels).sum().item()\n",
    "        total_prediction += prediction.shape[0]\n",
    "\n",
    "        #if i % 10 == 0:    # print every 10 mini-batches\n",
    "        #    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
    "    \n",
    "    # Print stats at the end of the epoch\n",
    "    num_batches = len(train_dl)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    acc = correct_prediction/total_prediction\n",
    "    inf = inference(myModel, val_dl)\n",
    "    print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}, Validation Accuracy: {inf[0]:.2f}')\n",
    "    if epoch==0 or epoch==19 or epoch==49 or epoch==99 or epoch==199:\n",
    "      confusion_matrix_func()\n",
    "\n",
    "    run[\"train/epoch/loss\"].log(avg_loss)\n",
    "    run[\"train/epoch/accuracy\"].log(acc)\n",
    "    run[\"train/epoch/inference\"].log(inf[0])\n",
    "\n",
    "  print('Finished Training')\n",
    "  \n",
    "  run.stop()\n",
    "  \n",
    "training(myModel, train_dl, num_epochs)\n",
    "date = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "torch.save(myModel.state_dict(), f'{date}_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed3cd24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T19:16:57.938565Z",
     "iopub.status.busy": "2022-07-12T19:16:57.938226Z",
     "iopub.status.idle": "2022-07-12T19:17:03.916035Z",
     "shell.execute_reply": "2022-07-12T19:17:03.915431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37, Total items: 470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3659574468085106,\n",
       " [[4, 0],\n",
       "  [4, 1],\n",
       "  [4, 0],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [0, 3],\n",
       "  [4, 0],\n",
       "  [0, 1],\n",
       "  [4, 1],\n",
       "  [0, 2],\n",
       "  [4, 0],\n",
       "  [2, 0],\n",
       "  [0, 4],\n",
       "  [0, 3],\n",
       "  [0, 3],\n",
       "  [0, 3],\n",
       "  [0, 2],\n",
       "  [0, 1],\n",
       "  [4, 0],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [4, 2],\n",
       "  [4, 2],\n",
       "  [0, 3],\n",
       "  [0, 1],\n",
       "  [4, 1],\n",
       "  [1, 4],\n",
       "  [4, 1],\n",
       "  [1, 3],\n",
       "  [1, 0],\n",
       "  [0, 3],\n",
       "  [1, 0],\n",
       "  [1, 0],\n",
       "  [2, 0],\n",
       "  [0, 1],\n",
       "  [4, 3],\n",
       "  [1, 3],\n",
       "  [4, 0],\n",
       "  [0, 1],\n",
       "  [0, 4],\n",
       "  [0, 3],\n",
       "  [0, 3],\n",
       "  [4, 2],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [4, 0],\n",
       "  [0, 1],\n",
       "  [4, 0],\n",
       "  [0, 3],\n",
       "  [0, 1],\n",
       "  [0, 3],\n",
       "  [4, 0],\n",
       "  [2, 4],\n",
       "  [0, 3],\n",
       "  [0, 3],\n",
       "  [0, 1],\n",
       "  [1, 3],\n",
       "  [0, 4],\n",
       "  [1, 3],\n",
       "  [0, 3],\n",
       "  [0, 3],\n",
       "  [4, 3],\n",
       "  [4, 0],\n",
       "  [1, 0],\n",
       "  [1, 0],\n",
       "  [4, 0],\n",
       "  [0, 1],\n",
       "  [4, 2],\n",
       "  [0, 3],\n",
       "  [2, 1],\n",
       "  [2, 0],\n",
       "  [2, 4],\n",
       "  [4, 0],\n",
       "  [4, 2],\n",
       "  [4, 0],\n",
       "  [0, 1],\n",
       "  [0, 2],\n",
       "  [0, 1],\n",
       "  [0, 3],\n",
       "  [0, 3],\n",
       "  [0, 1],\n",
       "  [4, 3],\n",
       "  [0, 2],\n",
       "  [0, 1],\n",
       "  [4, 2],\n",
       "  [0, 2],\n",
       "  [2, 4],\n",
       "  [0, 3],\n",
       "  [0, 1],\n",
       "  [0, 4],\n",
       "  [0, 1],\n",
       "  [0, 3],\n",
       "  [4, 2],\n",
       "  [4, 2],\n",
       "  [0, 3],\n",
       "  [0, 1],\n",
       "  [0, 3],\n",
       "  [0, 2],\n",
       "  [2, 4],\n",
       "  [0, 2],\n",
       "  [4, 0],\n",
       "  [0, 1],\n",
       "  [0, 2],\n",
       "  [4, 0],\n",
       "  [0, 4],\n",
       "  [4, 1],\n",
       "  [4, 2],\n",
       "  [1, 0],\n",
       "  [0, 3],\n",
       "  [1, 2],\n",
       "  [4, 2],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [0, 3],\n",
       "  [1, 3],\n",
       "  [4, 0],\n",
       "  [4, 2],\n",
       "  [0, 2],\n",
       "  [0, 3],\n",
       "  [0, 1],\n",
       "  [0, 4],\n",
       "  [4, 2],\n",
       "  [4, 2],\n",
       "  [0, 1],\n",
       "  [4, 0],\n",
       "  [4, 2],\n",
       "  [0, 4],\n",
       "  [4, 0],\n",
       "  [1, 3],\n",
       "  [0, 1],\n",
       "  [1, 0],\n",
       "  [0, 2],\n",
       "  [0, 1],\n",
       "  [1, 0],\n",
       "  [4, 2],\n",
       "  [4, 1],\n",
       "  [0, 3],\n",
       "  [0, 4],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [1, 0],\n",
       "  [2, 1],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [4, 2],\n",
       "  [4, 1],\n",
       "  [0, 1],\n",
       "  [2, 0],\n",
       "  [4, 0],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [0, 3],\n",
       "  [4, 0],\n",
       "  [4, 0],\n",
       "  [2, 1],\n",
       "  [0, 1],\n",
       "  [4, 1],\n",
       "  [0, 1],\n",
       "  [0, 3],\n",
       "  [0, 2],\n",
       "  [0, 4],\n",
       "  [0, 1],\n",
       "  [0, 3],\n",
       "  [0, 1],\n",
       "  [1, 0],\n",
       "  [0, 1],\n",
       "  [4, 2],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [4, 2],\n",
       "  [0, 3],\n",
       "  [0, 1],\n",
       "  [1, 3],\n",
       "  [0, 1],\n",
       "  [4, 1],\n",
       "  [4, 0],\n",
       "  [4, 3],\n",
       "  [1, 3],\n",
       "  [1, 3],\n",
       "  [4, 0],\n",
       "  [4, 1],\n",
       "  [0, 3],\n",
       "  [4, 2],\n",
       "  [0, 4],\n",
       "  [0, 3],\n",
       "  [0, 4],\n",
       "  [0, 3],\n",
       "  [4, 2],\n",
       "  [0, 3],\n",
       "  [1, 0],\n",
       "  [4, 2],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [0, 3],\n",
       "  [0, 3],\n",
       "  [4, 0],\n",
       "  [0, 2],\n",
       "  [1, 0],\n",
       "  [1, 3],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [4, 2],\n",
       "  [0, 1],\n",
       "  [2, 4],\n",
       "  [2, 3],\n",
       "  [0, 3],\n",
       "  [4, 0],\n",
       "  [0, 1],\n",
       "  [0, 3],\n",
       "  [4, 2],\n",
       "  [0, 1],\n",
       "  [2, 0],\n",
       "  [0, 1],\n",
       "  [4, 2],\n",
       "  [0, 4],\n",
       "  [0, 1],\n",
       "  [4, 2],\n",
       "  [0, 1],\n",
       "  [4, 0],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [2, 4],\n",
       "  [2, 0],\n",
       "  [0, 2],\n",
       "  [0, 4],\n",
       "  [0, 1],\n",
       "  [4, 2],\n",
       "  [0, 1],\n",
       "  [0, 4],\n",
       "  [0, 3],\n",
       "  [1, 3],\n",
       "  [4, 2],\n",
       "  [4, 3],\n",
       "  [4, 2],\n",
       "  [0, 3],\n",
       "  [2, 4],\n",
       "  [0, 1],\n",
       "  [0, 4],\n",
       "  [0, 3],\n",
       "  [4, 0],\n",
       "  [4, 0],\n",
       "  [0, 4],\n",
       "  [1, 0],\n",
       "  [0, 4],\n",
       "  [0, 2],\n",
       "  [4, 0],\n",
       "  [0, 2],\n",
       "  [0, 3],\n",
       "  [0, 1],\n",
       "  [2, 3],\n",
       "  [1, 3],\n",
       "  [0, 1],\n",
       "  [4, 2],\n",
       "  [4, 2],\n",
       "  [4, 2],\n",
       "  [1, 0],\n",
       "  [1, 0],\n",
       "  [4, 3],\n",
       "  [0, 3],\n",
       "  [0, 1],\n",
       "  [0, 3],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [4, 2],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [0, 3],\n",
       "  [0, 3],\n",
       "  [0, 3],\n",
       "  [0, 3],\n",
       "  [0, 3],\n",
       "  [4, 0],\n",
       "  [4, 0],\n",
       "  [4, 0],\n",
       "  [0, 4],\n",
       "  [0, 3],\n",
       "  [4, 0],\n",
       "  [0, 1],\n",
       "  [0, 4],\n",
       "  [0, 4],\n",
       "  [0, 1],\n",
       "  [0, 1],\n",
       "  [2, 0],\n",
       "  [0, 1],\n",
       "  [4, 2],\n",
       "  [0, 1],\n",
       "  [4, 0],\n",
       "  [0, 3],\n",
       "  [4, 3],\n",
       "  [0, 3],\n",
       "  [4, 0],\n",
       "  [0, 3],\n",
       "  [0, 4],\n",
       "  [0, 1],\n",
       "  [4, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inference (model, val_dl):\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "    wrong=[]\n",
    "\n",
    "  # Disable gradient updates\n",
    "    with torch.no_grad():\n",
    "        for data in val_dl:\n",
    "      # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "      # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "      # Get predictions\n",
    "            outputs = model(inputs)\n",
    "\n",
    "      # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            cpu_prediction = prediction.cpu().numpy()\n",
    "            cpu_labels = labels.cpu().numpy()\n",
    "            for i in range(len(cpu_prediction)):\n",
    "                if cpu_prediction[i]!=cpu_labels[i]:\n",
    "                    wrong.append([cpu_prediction[i],cpu_labels[i]])\n",
    "                    \n",
    "      # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "    #print(wrong)\n",
    "    acc = correct_prediction/total_prediction\n",
    "    print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
    "    return acc,wrong\n",
    "\n",
    "# Run inference on trained model with the validation set\n",
    "inference(myModel, val_dl)\n",
    "\n",
    "#add code to run inference on every epoch of the training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df8310f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T19:17:03.920106Z",
     "iopub.status.busy": "2022-07-12T19:17:03.918768Z",
     "iopub.status.idle": "2022-07-12T19:18:01.300264Z",
     "shell.execute_reply": "2022-07-12T19:18:01.299368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39, Total items: 470\n",
      "Accuracy: 0.40, Total items: 470\n",
      "Accuracy: 0.38, Total items: 470\n",
      "Accuracy: 0.36, Total items: 470\n",
      "Accuracy: 0.39, Total items: 470\n",
      "Accuracy: 0.40, Total items: 470\n",
      "Accuracy: 0.38, Total items: 470\n",
      "Accuracy: 0.39, Total items: 470\n",
      "Accuracy: 0.37, Total items: 470\n",
      "Accuracy: 0.37, Total items: 470\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "inc=[]\n",
    "for i in range(10):\n",
    "    val,wrong=inference(myModel, val_dl)\n",
    "    total.append(val)\n",
    "    inc.append(wrong)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a31ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T19:18:01.307096Z",
     "iopub.status.busy": "2022-07-12T19:18:01.305742Z",
     "iopub.status.idle": "2022-07-12T19:18:01.314741Z",
     "shell.execute_reply": "2022-07-12T19:18:01.314160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.21276595744681 +/- 0.10773607575465677 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"{100*np.mean(total)} +/- {100*(np.std(total)/len(total))} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21019cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T19:18:01.320009Z",
     "iopub.status.busy": "2022-07-12T19:18:01.318733Z",
     "iopub.status.idle": "2022-07-12T19:18:01.325018Z",
     "shell.execute_reply": "2022-07-12T19:18:01.324461Z"
    }
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71c2383d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T19:18:01.329987Z",
     "iopub.status.busy": "2022-07-12T19:18:01.328750Z",
     "iopub.status.idle": "2022-07-12T19:18:09.036012Z",
     "shell.execute_reply": "2022-07-12T19:18:09.035426Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/qlpd78/anaconda3/lib/python3.9/site-packages/torchaudio/functional/functional.py:507: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (513) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def confusion_matrix():\n",
    "  y_pred = []\n",
    "  y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "  for data in val_dl:\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "    inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "    output = myModel(inputs) # Feed Networ\n",
    "\n",
    "    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "    y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "    labels = labels.data.cpu().numpy()\n",
    "    y_true.extend(labels) # Save Truth\n",
    "#print(y_pred)\n",
    "#print(y_true)\n",
    "# constant for classes\n",
    "  classes = ('Stainless', 'Bright_Black', 'Tool', 'Galvanised', 'Engineering')\n",
    "\n",
    "# Build confusion matrix\n",
    "  cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "  df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10 , index = [i for i in classes],\n",
    "                      columns = [i for i in classes])\n",
    "  plt.figure(figsize = (12,7))\n",
    "  sn.heatmap(df_cm, annot=True)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "#print(cf_matrix)\n",
    "print(confusion_matrix())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "66151376c80f4b12cc505039e5c52131f5bf8a18ee8cc85403d0ef28f0b4953b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
